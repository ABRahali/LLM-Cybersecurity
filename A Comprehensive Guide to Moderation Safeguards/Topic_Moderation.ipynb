{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook provides an implementation of content moderation mechanisms aimed at ensuring safe and responsible interaction in a system. It includes:\n",
    "\n",
    "1. **Content Filters**: A mechanism that checks user input against a set of predefined blocked topics (such as violence, self-harm, or illegal activities). If any prohibited content is detected, it blocks the input from being processed.\n",
    "   \n",
    "2. **Denied Topics Handling**: If a user's input contains blocked topics, this feature provides a predefined response to guide the conversation away from harmful or restricted content.\n",
    "\n",
    "3. **Contextual Grounding Check**: This feature verifies that the generated content aligns with an approved knowledge base, ensuring that the responses are based on valid and factual information.\n",
    "\n",
    "These components collectively ensure that the system maintains a safe, ethical, and informative environment by filtering out harmful content and guiding user interactions in a responsible manner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1. Content Filters\n",
    "class ContentFilter:\n",
    "    def __init__(self, blocked_topics):\n",
    "        \"\"\"\n",
    "        Initializes the content filter with a list of prohibited topics.\n",
    "        :param blocked_topics: List of keywords or phrases to block.\n",
    "        \"\"\"\n",
    "        self.blocked_topics = [re.compile(topic, re.IGNORECASE) for topic in blocked_topics]\n",
    "\n",
    "    def is_allowed(self, text):\n",
    "        \"\"\"\n",
    "        Checks if the text contains any prohibited topics.\n",
    "        :param text: Input text to check.\n",
    "        :return: True if allowed, False if it contains blocked content.\n",
    "        \"\"\"\n",
    "        return not any(pattern.search(text) for pattern in self.blocked_topics)\n",
    "\n",
    "# 2. Denied Topics Handling\n",
    "class DeniedTopicsHandler:\n",
    "    def __init__(self, blocked_responses):\n",
    "        \"\"\"\n",
    "        Initializes the denied topics handler.\n",
    "        :param blocked_responses: Dictionary mapping denied topics to responses.\n",
    "        \"\"\"\n",
    "        self.blocked_responses = blocked_responses\n",
    "\n",
    "    def handle_denied_topic(self, text):\n",
    "        \"\"\"\n",
    "        Provides a response when a blocked topic is detected.\n",
    "        :param text: Input text to check.\n",
    "        :return: Appropriate response or None if the text is allowed.\n",
    "        \"\"\"\n",
    "        for topic, response in self.blocked_responses.items():\n",
    "            if re.search(topic, text, re.IGNORECASE):\n",
    "                return response\n",
    "        return None\n",
    "\n",
    "# 3. Contextual Grounding Check\n",
    "class ContextualGroundingChecker:\n",
    "    def __init__(self, approved_knowledge_base):\n",
    "        \"\"\"\n",
    "        Initializes the contextual grounding checker.\n",
    "        :param approved_knowledge_base: Set of approved knowledge entries.\n",
    "        \"\"\"\n",
    "        self.approved_knowledge_base = set(approved_knowledge_base)\n",
    "\n",
    "    def is_contextually_grounded(self, text):\n",
    "        \"\"\"\n",
    "        Checks if the content aligns with the approved knowledge base.\n",
    "        :param text: Text to check.\n",
    "        :return: True if grounded, False otherwise.\n",
    "        \"\"\"\n",
    "        return text in self.approved_knowledge_base\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Content Filter Example\n",
    "    filter = ContentFilter(blocked_topics=[\"violence\", \"self-harm\", \"illegal activities\"])\n",
    "    user_input = \"How to commit illegal activities?\"\n",
    "    if not filter.is_allowed(user_input):\n",
    "        print(\"Content blocked: Prohibited topic detected.\")\n",
    "    else:\n",
    "        print(\"Content allowed.\")\n",
    "\n",
    "    # 2. Denied Topics Handling Example\n",
    "    handler = DeniedTopicsHandler(\n",
    "        blocked_responses={\n",
    "            \"violence\": \"We cannot provide information on violent topics.\",\n",
    "            \"illegal activities\": \"Discussion of illegal activities is not permitted.\",\n",
    "        }\n",
    "    )\n",
    "    response = handler.handle_denied_topic(user_input)\n",
    "    if response:\n",
    "        print(\"Response:\", response)\n",
    "    else:\n",
    "        print(\"No blocked topics detected.\")\n",
    "\n",
    "    # 3. Contextual Grounding Check Example\n",
    "    grounding_checker = ContextualGroundingChecker(\n",
    "        approved_knowledge_base={\n",
    "            \"Artificial intelligence can assist with data analysis.\",\n",
    "            \"Climate change is a global issue requiring action.\",\n",
    "        }\n",
    "    )\n",
    "    generated_response = \"Artificial intelligence can assist with data analysis.\"\n",
    "    if grounding_checker.is_contextually_grounded(generated_response):\n",
    "        print(\"Content is contextually grounded.\")\n",
    "    else:\n",
    "        print(\"Content is not grounded in approved knowledge.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook demonstrates how to integrate content moderation into a system to safeguard interactions. By leveraging content filters, denied topic responses, and contextual grounding checks, we can ensure that the content produced by the system is both ethical and accurate. \n",
    "\n",
    "- The **Content Filter** blocks harmful or prohibited topics, preventing unsafe interactions.\n",
    "- The **Denied Topics Handler** ensures that users receive appropriate responses when attempting to discuss forbidden topics.\n",
    "- The **Contextual Grounding Checker** verifies that the content aligns with an approved knowledge base, ensuring factual integrity.\n",
    "\n",
    "Together, these mechanisms create a robust content moderation framework, helping to build safer and more reliable systems for users.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
