{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:23:58.094503Z","iopub.status.idle":"2024-12-26T06:23:58.094963Z","shell.execute_reply":"2024-12-26T06:23:58.094783Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport re\nfrom transformers import pipeline\nfrom datasets import load_dataset\nimport torch\n\n# Set your environment variables (API keys, if needed, for cloud models)\n# For Hugging Face models, you generally don’t need an API key unless using specific models on Hugging Face Hub\n\n# Step 1: Load Hugging Face's NER pipeline\n# We will use a pretrained BERT model for Named Entity Recognition (NER)\nner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n\n# Step 2: Define scrubbers for different types of PII\ndef scrub_phone_numbers(text: str) -> str:\n    return re.sub(r\"\\(?\\+?[0-9]*\\)?[-.\\s]?[0-9]+[-.\\s]?[0-9]+[-.\\s]?[0-9]+\", \"[REDACTED PHONE NUMBER]\", text)\n\ndef scrub_credit_card_numbers(text: str) -> str:\n    return re.sub(r\"\\b(?:\\d[ -]*?){13,16}\\b\", \"[REDACTED CREDIT CARD]\", text)\n\ndef scrub_email_addresses(text: str) -> str:\n    return re.sub(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\", \"[REDACTED EMAIL ADDRESS]\", text)\n\ndef scrub_postal_codes(text: str) -> str:\n    return re.sub(r\"\\b\\d{5}(-\\d{4})?\\b\", \"[REDACTED POSTAL CODE]\", text)\n\ndef scrub_sin_numbers(text: str) -> str:\n    return re.sub(r\"\\b\\d{3}-\\d{3}-\\d{3}\\b\", \"[REDACTED SIN]\", text)\n\n# Combine all scrubbers into a list\nALL_SCRUBBERS = [\n    scrub_phone_numbers,\n    scrub_credit_card_numbers,\n    scrub_email_addresses,\n    scrub_postal_codes,\n    scrub_sin_numbers,\n]\n\n# Step 3: Function to apply all scrubbers to input text\ndef apply_scrubbers(text: str) -> str:\n    \"\"\"\n    Apply all predefined scrubbers to the input text.\n    \"\"\"\n    for scrubber in ALL_SCRUBBERS:\n        text = scrubber(text)\n    return text\n\n# Step 4: Function to detect PII using Hugging Face's NER pipeline\ndef detect_pii_with_huggingface(text: str):\n    \"\"\"\n    This function uses Hugging Face's NER model to detect PII in the text.\n    \"\"\"\n    # Detect named entities using Hugging Face's NER pipeline\n    ner_results = ner_pipeline(text)\n    \n    # Filter out non-PII entities (e.g., labels other than 'PER' for persons, 'ORG' for organizations)\n    pii_entities = [entity for entity in ner_results if entity['entity'] in ['PER', 'LOC', 'ORG', 'MISC']]\n    \n    return pii_entities\n\n# Step 5: Set up a function to send a request to a Hugging Face model (e.g., summarization or generation)\ndef send_huggingface_request(text: str, model=\"facebook/bart-large-cnn\", max_tokens=50):\n    \"\"\"\n    Sends a request to a Hugging Face model after scrubbing PII.\n    \"\"\"\n    # Step 5.1: Detect and scrub PII using Hugging Face's NER model\n    detected_pii = detect_pii_with_huggingface(text)\n    scrubbed_text = apply_scrubbers(text)\n    \n    # Step 5.2: Load the Hugging Face model (for text summarization or generation)\n    summarizer = pipeline(\"summarization\", model=model)\n    \n    # Step 5.3: Generate a summary of the scrubbed text\n    summary = summarizer(scrubbed_text, max_length=max_tokens, min_length=25, do_sample=False)\n    \n    return summary, detected_pii\n\n# Step 6: Example usage of the function with a sample input\nexample_text = \"Michael Smith (msmith@gmail.com, (+1) 111-111-1111) committed a mistake when he used PyTorch Trainer instead of HF Trainer.\"\n\n# Send the request and print the response\nsummary, detected_pii = send_huggingface_request(\n    text=f\"{example_text}\\n\\nSummarize the above text in 1-2 sentences.\"\n)\nprint(\"Summary:\", summary)\nprint(\"Detected PII:\", detected_pii)\n\n# Step 7: Testing PII Scrubbing on Real Data (Optional)\n# You can load a dataset containing PII and apply the scrubbing mechanism to it\n\n# Load the AI4Privacy PII Masking dataset\npii_ds = load_dataset(\"ai4privacy/pii-masking-200k\")\n\n# Example input from the dataset\nexample_text = pii_ds[\"train\"][36][\"source_text\"]\n\n# Send the request with the scrubbed dataset example\nsummary, detected_pii = send_huggingface_request(\n    text=f\"{example_text}\\n\\nSummarize the above text in 1-2 sentences.\"\n)\nprint(\"Summary:\", summary)\nprint(\"Detected PII:\", detected_pii)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:33:05.977760Z","iopub.execute_input":"2024-12-26T06:33:05.978233Z","iopub.status.idle":"2024-12-26T06:33:52.580005Z","shell.execute_reply.started":"2024-12-26T06:33:05.978200Z","shell.execute_reply":"2024-12-26T06:33:52.578676Z"}},"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d361b04c3f145739d207f2a76de28d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"697719905a5644d18aea08cfa6fd8b58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b038b21f0153415782fb1321f806563b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"187c554b58524e14943b03a9c6c90812"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44c69da27ebb48769e47e18ac46ef67f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf8c7b94fa994ba383a723eb4f563837"}},"metadata":{}},{"name":"stderr","text":"Your max_length is set to 50, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n","output_type":"stream"},{"name":"stdout","text":"Summary: [{'summary_text': 'Michael Smith committed a mistake when he used PyTorch Trainer instead of HF Trainer. He used the wrong name for the training program.'}]\nDetected PII: []\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/12.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebdf9a94f7b4463b866fdc7013325a03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"english_pii_43k.jsonl:   0%|          | 0.00/73.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d523aa02034782af027a606e198286"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"french_pii_62k.jsonl:   0%|          | 0.00/116M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e1e3e6d342248e392957b760e625176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"german_pii_52k.jsonl:   0%|          | 0.00/97.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"094a43ecef8a4cc3ab9675fb1b6c1e7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"italian_pii_50k.jsonl:   0%|          | 0.00/93.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a8fa2e20b449a4870fb70a17328f3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/209261 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f6a696856e7403fac790a73721c36d7"}},"metadata":{}},{"name":"stdout","text":"Summary: [{'summary_text': \"I need the latest update on assessment results. Please send the files to [REDACTED EMAIL ADDRESS]. For your extra time, we'll offer you Kip[REDACTED PHONE NUMBER]. But please provide your л\"}]\nDetected PII: []\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"!pip install presidio-analyzer presidio-anonymizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:28:25.013762Z","iopub.execute_input":"2024-12-26T06:28:25.014277Z","iopub.status.idle":"2024-12-26T06:28:30.001222Z","shell.execute_reply.started":"2024-12-26T06:28:25.014234Z","shell.execute_reply":"2024-12-26T06:28:29.999827Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: presidio-analyzer in /usr/local/lib/python3.10/dist-packages (2.2.356)\nCollecting presidio-anonymizer\n  Downloading presidio_anonymizer-2.2.356-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: phonenumbers<9.0.0,>=8.12 in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (8.13.52)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (6.0.2)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (2024.9.11)\nRequirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (3.7.6)\nRequirement already satisfied: tldextract in /usr/local/lib/python3.10/dist-packages (from presidio-analyzer) (5.1.3)\nCollecting azure-core (from presidio-anonymizer)\n  Downloading azure_core-1.32.0-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: pycryptodome>=3.10.1 in /usr/local/lib/python3.10/dist-packages (from presidio-anonymizer) (3.21.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.12.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (4.66.5)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.9.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.1.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (71.0.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (24.1)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.26.4)\nRequirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio-anonymizer) (1.16.0)\nRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-core->presidio-anonymizer) (4.12.2)\nRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio-analyzer) (3.10)\nRequirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio-analyzer) (2.1.0)\nRequirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio-analyzer) (3.16.1)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.23.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (13.8.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.1.5)\nRequirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (2.18.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio-analyzer) (0.1.2)\nDownloading presidio_anonymizer-2.2.356-py3-none-any.whl (31 kB)\nDownloading azure_core-1.32.0-py3-none-any.whl (198 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.9/198.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: azure-core, presidio-anonymizer\nSuccessfully installed azure-core-1.32.0 presidio-anonymizer-2.2.356\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# 1. Import necessary libraries\n\n# Presidio is for PII detection and redaction\nfrom presidio_analyzer import AnalyzerEngine\nfrom presidio_anonymizer import AnonymizerEngine, OperatorConfig\nfrom presidio_analyzer import RecognizerResult\n\n# Hugging Face's transformers for NER (Named Entity Recognition)\nfrom transformers import pipeline\n\n# 2. Setup Presidio Analyzer\n\n# Initialize Presidio's AnalyzerEngine, which will detect various PII categories\nanalyzer = AnalyzerEngine()\n\n# List available PII recognizers in Presidio\navailable_recognizers = analyzer.get_recognizers()\nprint(\"Available recognizers in Presidio:\", [r.name for r in available_recognizers])\n\n# 3. Setup Hugging Face for NER\n\n# Using Hugging Face pipeline for Named Entity Recognition (NER)\nner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n\n# 4. Function to detect and redact PII using Presidio\n\ndef detect_and_redact_pii_with_presidio(text: str):\n    \"\"\"\n    This function uses Presidio to detect and redact PII from the text.\n    \"\"\"\n    # Analyze the text to detect PII\n    results = analyzer.analyze(text=text, language='en')\n    \n    # Create an anonymizer engine\n    anonymizer = AnonymizerEngine()\n    \n    # Redact detected PII\n    anonymized_text = anonymizer.anonymize(text, results)\n    \n    # Return the anonymized text and detected entities\n    return anonymized_text, results\n\n# Example input text with PII\ninput_text = \"John Doe's email is john.doe@example.com and his phone number is +1234567890.\"\n\n# Detect and redact PII using Presidio\nanonymized_text_presidio, detected_pii_presidio = detect_and_redact_pii_with_presidio(input_text)\nprint(\"Anonymized text using Presidio:\", anonymized_text_presidio)\n\n# 5. Function to detect PII using Hugging Face's NER pipeline\n\nfrom transformers import pipeline\n\n# Using Hugging Face's NER pipeline\nner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n\n# Function to detect PII using Hugging Face's NER pipeline\ndef detect_pii_with_huggingface(text: str):\n    \"\"\"\n    This function uses Hugging Face's NER model to detect PII in the text.\n    \"\"\"\n    # Detect named entities using Hugging Face's NER pipeline\n    ner_results = ner_pipeline(text)\n    \n    # Filter out non-PII entities (e.g., labels other than 'PER' for persons, 'ORG' for organizations)\n    pii_entities = [entity for entity in ner_results if entity['entity'] in ['PER', 'LOC', 'ORG', 'MISC']]\n    \n    return pii_entities\n\n# Example input text with PII\ninput_text = \"John Doe's email is john.doe@example.com and his phone number is +1234567890.\"\n\n# Detect PII using Hugging Face\ndetected_pii_huggingface = detect_pii_with_huggingface(input_text)\nprint(\"Detected PII using Hugging Face:\", detected_pii_huggingface)\n\n\n# Detect PII using Hugging Face\ndetected_pii_huggingface = detect_pii_with_huggingface(input_text)\nprint(\"Detected PII using Hugging Face:\", detected_pii_huggingface)\n\n# 6. Compare the results from both methods\n\nprint(\"Comparing Presidio and Hugging Face NER Results:\")\nprint(f\"Presidio detected PII: {detected_pii_presidio}\")\nprint(f\"Hugging Face detected PII: {detected_pii_huggingface}\")\n\n# 7. Customizing Presidio for specific PII types\n\n# Example: Adding custom recognizers or modifying existing ones\ncustom_recognizers = analyzer.get_recognizers()\nprint(\"Customizable Recognizers:\", custom_recognizers)\n\n# Presidio allows customization of the recognizers, for example, to redact specific keywords\ndef custom_pii_redaction(text: str):\n    \"\"\"\n    Custom PII redaction using custom recognizers in Presidio\n    \"\"\"\n    custom_results = analyzer.analyze(text=text, language='en')\n    custom_anonymizer = AnonymizerEngine()\n    custom_anonymized_text = custom_anonymizer.anonymize(text, custom_results)\n    return custom_anonymized_text\n\n# Example input with custom text\ncustom_input_text = \"Jane Doe was seen at 1234 Elm Street and her email is jane.doe@customdomain.com.\"\ncustom_anonymized_text = custom_pii_redaction(custom_input_text)\nprint(\"Custom Anonymized text using Presidio:\", custom_anonymized_text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T06:30:44.231405Z","iopub.execute_input":"2024-12-26T06:30:44.231863Z","iopub.status.idle":"2024-12-26T06:30:48.564897Z","shell.execute_reply.started":"2024-12-26T06:30:44.231830Z","shell.execute_reply":"2024-12-26T06:30:48.563800Z"}},"outputs":[{"name":"stdout","text":"Available recognizers in Presidio: ['UsBankRecognizer', 'SpacyRecognizer', 'AuAbnRecognizer', 'IbanRecognizer', 'InAadhaarRecognizer', 'InPanRecognizer', 'AuMedicareRecognizer', 'InPassportRecognizer', 'MedicalLicenseRecognizer', 'PhoneRecognizer', 'InVehicleRegistrationRecognizer', 'CryptoRecognizer', 'IpRecognizer', 'UsItinRecognizer', 'SgFinRecognizer', 'UsLicenseRecognizer', 'UrlRecognizer', 'AuTfnRecognizer', 'DateRecognizer', 'UsSsnRecognizer', 'EmailRecognizer', 'AuAcnRecognizer', 'UsPassportRecognizer', 'NhsRecognizer', 'InVoterRecognizer', 'UkNinoRecognizer', 'CreditCardRecognizer']\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"Anonymized text using Presidio: text: <PERSON> email is <EMAIL_ADDRESS> and his phone number is +<US_BANK_NUMBER>.\nitems:\n[\n    {'start': 59, 'end': 75, 'entity_type': 'US_BANK_NUMBER', 'text': '<US_BANK_NUMBER>', 'operator': 'replace'},\n    {'start': 18, 'end': 33, 'entity_type': 'EMAIL_ADDRESS', 'text': '<EMAIL_ADDRESS>', 'operator': 'replace'},\n    {'start': 0, 'end': 8, 'entity_type': 'PERSON', 'text': '<PERSON>', 'operator': 'replace'}\n]\n\n","output_type":"stream"},{"name":"stderr","text":"Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"name":"stdout","text":"Detected PII using Hugging Face: []\nDetected PII using Hugging Face: []\nComparing Presidio and Hugging Face NER Results:\nPresidio detected PII: [type: EMAIL_ADDRESS, start: 20, end: 40, score: 1.0, type: PERSON, start: 0, end: 10, score: 0.85, type: URL, start: 20, end: 27, score: 0.5, type: URL, start: 29, end: 40, score: 0.5, type: US_BANK_NUMBER, start: 66, end: 76, score: 0.05, type: US_DRIVER_LICENSE, start: 66, end: 76, score: 0.01]\nHugging Face detected PII: []\nCustomizable Recognizers: [<presidio_analyzer.predefined_recognizers.us_bank_recognizer.UsBankRecognizer object at 0x7fb493b1d810>, <presidio_analyzer.predefined_recognizers.spacy_recognizer.SpacyRecognizer object at 0x7fb493b1d840>, <presidio_analyzer.predefined_recognizers.au_abn_recognizer.AuAbnRecognizer object at 0x7fb493b1d870>, <presidio_analyzer.predefined_recognizers.iban_recognizer.IbanRecognizer object at 0x7fb493b1d8a0>, <presidio_analyzer.predefined_recognizers.in_aadhaar_recognizer.InAadhaarRecognizer object at 0x7fb493b1d900>, <presidio_analyzer.predefined_recognizers.in_pan_recognizer.InPanRecognizer object at 0x7fb493b1d930>, <presidio_analyzer.predefined_recognizers.au_medicare_recognizer.AuMedicareRecognizer object at 0x7fb493b1d960>, <presidio_analyzer.predefined_recognizers.in_passport_recognizer.InPassportRecognizer object at 0x7fb493b1d9c0>, <presidio_analyzer.predefined_recognizers.medical_license_recognizer.MedicalLicenseRecognizer object at 0x7fb493b1d9f0>, <presidio_analyzer.predefined_recognizers.phone_recognizer.PhoneRecognizer object at 0x7fb493b1fa00>, <presidio_analyzer.predefined_recognizers.in_vehicle_registration_recognizer.InVehicleRegistrationRecognizer object at 0x7fb493b1da20>, <presidio_analyzer.predefined_recognizers.crypto_recognizer.CryptoRecognizer object at 0x7fb493b1da50>, <presidio_analyzer.predefined_recognizers.ip_recognizer.IpRecognizer object at 0x7fb493b1dab0>, <presidio_analyzer.predefined_recognizers.us_itin_recognizer.UsItinRecognizer object at 0x7fb493b1d300>, <presidio_analyzer.predefined_recognizers.sg_fin_recognizer.SgFinRecognizer object at 0x7fb493b1d330>, <presidio_analyzer.predefined_recognizers.us_driver_license_recognizer.UsLicenseRecognizer object at 0x7fb493b1d360>, <presidio_analyzer.predefined_recognizers.url_recognizer.UrlRecognizer object at 0x7fb493b1dba0>, <presidio_analyzer.predefined_recognizers.au_tfn_recognizer.AuTfnRecognizer object at 0x7fb493b1d3c0>, <presidio_analyzer.predefined_recognizers.date_recognizer.DateRecognizer object at 0x7fb493b1dbd0>, <presidio_analyzer.predefined_recognizers.us_ssn_recognizer.UsSsnRecognizer object at 0x7fb493b1d3f0>, <presidio_analyzer.predefined_recognizers.email_recognizer.EmailRecognizer object at 0x7fb493b1dc00>, <presidio_analyzer.predefined_recognizers.au_acn_recognizer.AuAcnRecognizer object at 0x7fb493b1d450>, <presidio_analyzer.predefined_recognizers.us_passport_recognizer.UsPassportRecognizer object at 0x7fb493b1d4b0>, <presidio_analyzer.predefined_recognizers.uk_nhs_recognizer.NhsRecognizer object at 0x7fb493b1d570>, <presidio_analyzer.predefined_recognizers.in_voter_recognizer.InVoterRecognizer object at 0x7fb493b1de10>, <presidio_analyzer.predefined_recognizers.uk_nino_recognizer.UkNinoRecognizer object at 0x7fb493b1d720>, <presidio_analyzer.predefined_recognizers.credit_card_recognizer.CreditCardRecognizer object at 0x7fb50212bfa0>]\nCustom Anonymized text using Presidio: text: <PERSON> was seen at <LOCATION> and her email is <EMAIL_ADDRESS>.\nitems:\n[\n    {'start': 49, 'end': 64, 'entity_type': 'EMAIL_ADDRESS', 'text': '<EMAIL_ADDRESS>', 'operator': 'replace'},\n    {'start': 21, 'end': 31, 'entity_type': 'LOCATION', 'text': '<LOCATION>', 'operator': 'replace'},\n    {'start': 0, 'end': 8, 'entity_type': 'PERSON', 'text': '<PERSON>', 'operator': 'replace'}\n]\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}